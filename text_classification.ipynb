{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZRWFgnGlpSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "import random\n",
        "import pickle,sklearn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKfvPzg0mGql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "3f20242a-1f19-4f07-d7b3-145f749afe43"
      },
      "source": [
        "nltk.download('movie_reviews')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtT5Tgi2l52s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "'''Creating Training Data'''\n",
        "documents = [(list(movie_reviews.words(fileid)),category) for category in movie_reviews.categories() for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "\"\"\"shuffling all the training data so that the model does not train on all positive or all negative data at the same time\"\"\"\n",
        "random.shuffle(documents)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FCJIUMjxmWd",
        "colab_type": "text"
      },
      "source": [
        "Function for creating Feature set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu4mcgdqxlab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_feature(document):\n",
        "    document = set(document)\n",
        "    feature = {}\n",
        "    for word in document:\n",
        "        feature[word] = (word in most_occured)\n",
        "    \n",
        "    return feature"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ODlgdi50Ix4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_words = []\n",
        "punctuation = [',','.','-',')','(']\n",
        "\n",
        "for word in movie_reviews.words():\n",
        "    if word not in punctuation:\n",
        "        all_words.append(word.lower())\n",
        "    \n",
        "\"\"\"FreqDist gives a list of tuples of Dictionary of the words and their frequency\"\"\"\n",
        "all_words = nltk.FreqDist(all_words)\n",
        "\n",
        "most_occured = list(all_words.keys())[:3000]\n",
        "'''Creating a feature set of words and the boolean of their existence in the document'''\n",
        "\n",
        "featureset = [(find_feature(review),category) for (review,category) in documents]\n",
        "\n",
        "train_set = featureset[:1600]\n",
        "test_set = featureset[1600:]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn6EG7Ha1FPA",
        "colab_type": "text"
      },
      "source": [
        "Naive bayes Algorithm.\n",
        "\n",
        "posterior = prior occurence x likelihood / evidence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npVhGkCj043A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "979b35d3-db93-4bc8-9bf8-9e75ac7f491f"
      },
      "source": [
        "'''Training the classifier for the first time and checking the accuracy of the trained classifier'''\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "'''using the previously trained classifier'''\n",
        "#classifier_trained = open('naivebayes.pickle','rb')\n",
        "#classifier = pickle.load(classifier_trained)\n",
        "#classifier_trained.close()\n",
        "\n",
        "print('Accuracy =',nltk.classify.accuracy(classifier, test_set)*100,'%')\n",
        "classifier.show_most_informative_features(15)\n",
        "\n",
        "'''saving the trained classifier using pickle so that we need not train the model again and the time taken is low'''\n",
        "#save_classifier = open('naivebayes.pickle','wb')\n",
        "#pickle.dump(classifier,save_classifier)\n",
        "#save_classifier.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 77.5 %\n",
            "Most Informative Features\n",
            "             outstanding = False             pos : neg    =     14.4 : 1.0\n",
            "               atrocious = True              neg : pos    =     10.8 : 1.0\n",
            "                  seagal = False             neg : pos    =     10.8 : 1.0\n",
            "                captures = False             pos : neg    =     10.8 : 1.0\n",
            "                    slip = False             pos : neg    =     10.5 : 1.0\n",
            "               stupidity = False             neg : pos    =     10.4 : 1.0\n",
            "              unbearable = False             neg : pos    =     10.2 : 1.0\n",
            "                    jedi = False             pos : neg    =      9.8 : 1.0\n",
            "                    taxi = False             pos : neg    =      9.8 : 1.0\n",
            "               animators = False             pos : neg    =      9.8 : 1.0\n",
            "              astounding = False             pos : neg    =      9.8 : 1.0\n",
            "                composer = False             pos : neg    =      9.8 : 1.0\n",
            "                  avoids = False             pos : neg    =      9.8 : 1.0\n",
            "               painfully = True              neg : pos    =      9.7 : 1.0\n",
            "               exquisite = False             pos : neg    =      9.2 : 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'saving the trained classifier using pickle so that we need not train the model again and the time taken is low'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU799Sm68AWG",
        "colab_type": "text"
      },
      "source": [
        "Predicting the test Data after the training (using Naive Bayes Classifier.classify attribute)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrOS8XqRJdFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7539ef8f-01ab-4386-91ed-dc487e88672b"
      },
      "source": [
        "predicted = classifier.classify(test_set[len(test_set)-1][0])\n",
        "print('predicted =',predicted,'True =',test_set[len(test_set)-1][1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted = pos True = pos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v-7X82ciwae",
        "colab_type": "text"
      },
      "source": [
        "Predicting the revies from a txt file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGi9Dy4GwWaG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6d30129a-1ea5-4231-9372-8b82a245edae"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "'''nltk.download('punkt')'''"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"nltk.download('punkt')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdEw2IcLzAEZ",
        "colab_type": "text"
      },
      "source": [
        "Here we input the files whose output we want to predict.\n",
        "I have input same nltk files with their true labels as their name. One can also use individual files for the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwBPX3HkivO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dict = []\n",
        "for i in ['neg','pos']:\n",
        "  for k in range(1,5):\n",
        "    with open (i+str(k)+\".txt\", \"r\") as file:\n",
        "      data = word_tokenize(file.read().replace('\\n', ''))\n",
        "      Dict.append((find_feature(data),i))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHxSnUps0ghd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "5e3a54f5-15e5-46c0-f833-a9e61ddb3b14"
      },
      "source": [
        "for files in Dict:\n",
        "  predicted = classifier.classify(files[0])\n",
        "  print('predicted =',predicted,'True =',files[1])  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted = neg True = neg\n",
            "predicted = neg True = neg\n",
            "predicted = neg True = neg\n",
            "predicted = neg True = neg\n",
            "predicted = pos True = pos\n",
            "predicted = pos True = pos\n",
            "predicted = pos True = pos\n",
            "predicted = pos True = pos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6kBppQM25Dm",
        "colab_type": "text"
      },
      "source": [
        "The next part includes some extra Classifiers provided by SKlearn which can be used since they have higher Accuracy than the Naive Bayes Classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHbcqBz24Epz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' sklearn wrapper around nltk'''\n",
        "from nltk.classify.scikitlearn import SklearnClassifier"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiDbPlrx3Srl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e86d08d7-ceea-4280-c0f2-acdd78cd8109"
      },
      "source": [
        "'''using MultinomialNB, GaussianNB and BernoulliNB naive bayes Algorithms around SklearnClassifier'''\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "\n",
        "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
        "MNB_classifier.train(train_set)\n",
        "\n",
        "BNB_classifier = SklearnClassifier(BernoulliNB())\n",
        "BNB_classifier.train(train_set)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgQ8T5rriZlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "eda93b9c-1fde-44c3-ca41-a85d61d7d437"
      },
      "source": [
        "print('Accuracy for MNB_CLassifier =',nltk.classify.accuracy(MNB_classifier, test_set)*100,'%')\n",
        "print('Accuracy for BNB_CLassifier =',nltk.classify.accuracy(BNB_classifier, test_set)*100,'%')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for MNB_CLassifier = 84.75 %\n",
            "Accuracy for BNB_CLassifier = 84.5 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}